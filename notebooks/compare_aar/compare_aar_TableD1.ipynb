{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "\n",
    "from ak_diseq.glacierData import glacierData\n",
    "from ak_diseq.utils import weighted_quantile, hist2\n",
    "\n",
    "plt.style.use('default')\n"
   ],
   "id": "ba17d3cd4ddb8cdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Zeller dataset\n",
    "elas = pd.read_csv(Path('data/zeller/alaska_elas.csv'))\n",
    "print(elas.head(5))\n",
    "elas.aar.describe()"
   ],
   "id": "8a0ddeafb91dc2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 0.4, 0.6, and Zeller 2024 AAR.\n",
    "gd_aar40 = glacierData(aar=0.4)\n",
    "gd_aar60 = glacierData(aar=0.6)\n",
    "gd_aarZ = glacierData(aar=\"zeller\")\n",
    "gds = {\n",
    "    \"0.4\": gd_aar40,\n",
    "    \"0.6\": gd_aar60,\n",
    "    'zeller': gd_aarZ\n",
    "}\n",
    "ds = {}\n",
    "for key, gd in gds.items():\n",
    "    gd.calc_response_time()\n",
    "    gd.calc_linear_feq()\n",
    "    gd.calc_feq()\n",
    "    ds[key] = gd.rgi"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "5777c23aac5940a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for aar, d in ds.items():\n",
    "    print(aar, len(d))"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "90a1548c1f6b644d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#d.apply(lambda x: x['Zela'] - x['z'][x['Zela_idx']], axis=1)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for aar, d in ds.items():\n",
    "    sns.histplot(d['bt'], label=aar, fill=False, ax=ax, bins=np.linspace(-20, 1, 40), element='step')\n",
    "    print(f\"\\n{aar}\")\n",
    "    print(\"Median:\", weighted_quantile(d[\"bt\"], [0.05, 0.5, 0.95])) \n",
    "    print(\"weighted median:\", weighted_quantile(d[\"bt\"], [0.05, 0.5, 0.95], sample_weight=d[\"Area\"]))\n",
    "    print(\"Std:\", d['bt'].std())\n",
    "    print(\"Skew:\", d['bt'].skew())\n",
    "ax.legend()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "9025b828568eef1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "binfreq = 0.25\n",
    "for aar, d in ds.items():\n",
    "    x = d['bt']\n",
    "    uwpdf, bins = hist2(x, binfreq=binfreq, cumsum=False, from_zero=True)\n",
    "    awcdf, bins = hist2(x, area=d['Area'].to_numpy(), binfreq=binfreq, cumsum=True, from_zero=True)\n",
    "    ax[0].step(bins, uwpdf, label=aar)\n",
    "    ax[1].step(bins, awcdf)\n",
    "    ax[0].legend()\n",
    "    ax[1].set_xlabel(\"bt [m yr-1]\")\n",
    "    \n",
    "    print(f\"\\n{aar}\")\n",
    "    print(\"Median:\", weighted_quantile(x, [0.05, 0.5, 0.95])) \n",
    "    print(\"weighted median:\", weighted_quantile(x, [0.05, 0.5, 0.95], sample_weight=d[\"Area\"]))\n",
    "    print(\"Std:\", x.std())\n",
    "    print(\"Skew:\", x.skew())"
   ],
   "id": "13b698d70b38184b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "ds_plt = {key: df.loc[:, [\"Area\", \"bt\", \"Zela\", \"RGIId\"]] for key, df in ds.items()}\n",
    "d = ds_plt[\"0.4\"]\n",
    "qcuts = pd.cut(d['Area'], bins=[1,2, 5, 10, 25, 50, 100, 250, 1000, 10000], precision=0)\n",
    "\n",
    "for key in [\"0.6\", \"zeller\"]:\n",
    "    d_merge = ds_plt[key][[col for col in ds_plt[key] if col not in ['Area']]]  # get the df from the dict of cases\n",
    "    print(key)\n",
    "    print(d.columns)\n",
    "    print(d_merge.columns)\n",
    "    d = d.merge(d_merge, on=[\"RGIId\"], suffixes=[\"_0.4\", f\"_{key}\"])  #\n",
    "    print(d.columns)\n",
    "d = d.rename(columns={\"bt\": \"bt_zeller\", \"Zela\": \"Zela_zeller\", \"aar\": \"aar_zeller\"})\n",
    "print(d.columns)\n",
    "d[\"qcut\"] = qcuts\n",
    "# Reshape the DataFrame using melt for Seaborn plotting\n",
    "d = pd.melt(\n",
    "    d,\n",
    "    id_vars=[\"RGIId\", \"Area\", \"qcut\"],\n",
    "    value_vars=[col for col in d.columns if col not in [\"RGIId\", \"Area\" \"qcut\"]],\n",
    "    var_name=\"variable\",\n",
    "    value_name=\"value\"\n",
    ")\n",
    "\n",
    "print(d.columns)\n",
    "# Extract suffixes and assign them as a new column for hue\n",
    "d[\"suffix\"] = d[\"variable\"].apply(lambda x: x.split(\"_\")[-1]).astype(str)\n",
    "d[\"variable\"] = d[\"variable\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "\n",
    "print(d.columns)\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained', dpi=200)\n",
    "sns.boxplot(data=d.loc[d.variable == \"bt\"], x=\"qcut\", y=\"value\", hue='suffix', ax=ax, hue_order=[\"zeller\", \"0.4\", \"0.6\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "(\n",
    "    so.Plot(x=qcuts.cat.categories, y=0, text=[f\"{item:.0f}\" for item in qcuts.value_counts().values/2])\n",
    "    .add(so.Text(fontsize='xx-small',valign='top', offset=5))\n",
    "    .on(ax)\n",
    "    .plot()\n",
    ")\n",
    "ax.grid(which='both', axis='y')\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(4))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(1))\n",
    "ax.set_ylim([-20, 1])\n",
    "ax.set_xlabel('Area (km2)')\n",
    "ax.set_ylabel('bt (m swe yr^-1)')"
   ],
   "id": "5b74a5ad94a5a620",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "Zela_mean = d.loc[d.variable == \"Zela\"].groupby(\"suffix\").mean(numeric_only=True)\n",
    "Zela_mean = Zela_mean[\"value\"]\n",
    "\n",
    "print(\"Mean Zela:\", Zela_mean)\n",
    "\n",
    "diff = (Zela_mean[\"0.4\"] - Zela_mean[\"0.6\"])\n",
    "print(\"Pct. diff (0.4 - 0.6): \", diff/Zela_mean[\"0.6\"]) \n",
    "print(\"Diff (0.4 - 0.6)\",diff, \"\\n\")\n",
    "\n",
    "diff = (Zela_mean[\"zeller\"] - Zela_mean[\"0.4\"])\n",
    "print(\"Pct. diff (Zeller - 0.4): \", diff/Zela_mean[\"0.4\"]) \n",
    "print(\"Diff (Zeller - 0.4): \", diff)"
   ],
   "id": "7f6d9b92701b2d68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Area-weighted ela\n",
    "dd = d.loc[d.variable == \"Zela\"].groupby(\"suffix\").apply(lambda x: weighted_quantile(x[\"value\"], [0.05, 0.5, 0.95]), include_groups=False)\n",
    "\n",
    "dd_aw = d.loc[d.variable == \"Zela\"].groupby(\"suffix\").apply(lambda x: weighted_quantile(x[\"value\"], [0.05, 0.5, 0.95], sample_weight=x[\"Area\"]), include_groups=False)\n",
    "\n",
    "print(\"Number weighted:\")\n",
    "print(dd, \"\\n\")\n",
    "\n",
    "print(\"Area weighted:\")\n",
    "print(dd_aw)"
   ],
   "id": "d6852566e3b0fa6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "dd = d.loc[d.variable == \"Zela\"]\n",
    "print(\"Median Zela:\", weighted_quantile(dd[\"value\"], [0.05, 0.5, 0.95]))\n",
    "print(\"Weighted median Zela:\", weighted_quantile(dd[\"value\"], [0.05, 0.5, 0.95], sample_weight=dd[\"Area\"]))"
   ],
   "id": "4b26d43e7bed307",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# what is the pct difference in bt for each glacier?\n",
    "dd = d.loc[d.variable == \"bt\"]\n",
    "dd = dd.pivot_table(columns=['suffix'], index=[\"RGIId\", \"Area\"], values='value').reset_index()\n",
    "diff = dd[\"0.4\"]/dd[\"0.6\"] - 1\n",
    "print(diff.describe())\n",
    "print(\"Weighted medianx pct diff:\", weighted_quantile(diff, [0.05, 0.5, 0.95], sample_weight=dd[\"Area\"]))\n",
    "\n",
    "diff = dd[\"zeller\"]/dd[\"0.4\"] - 1\n",
    "print(diff.describe())\n",
    "print(\"Weighted median pct diff:\", weighted_quantile(diff, [0.05, 0.5, 0.95], sample_weight=dd[\"Area\"]))"
   ],
   "id": "a886a4cac9c8b61f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#d.apply(lambda x: x['Zela'] - x['z'][x['Zela_idx']], axis=1)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for aar, d in ds.items():\n",
    "    sns.histplot(d['tau'], label=aar, fill=False, ax=ax, bins=np.linspace(0, 100, 40), element='step')\n",
    "ax.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "3c094d770887c146",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(2,1, sharex=True)\n",
    "binfreq = 2.5\n",
    "for aar, d in ds.items():\n",
    "    x = d['tau']\n",
    "    uwpdf, bins = hist2(x, binfreq=binfreq, cumsum=False, from_zero=True)\n",
    "    awcdf, bins = hist2(x, area=d['Area'].to_numpy(), binfreq=binfreq, cumsum=True, from_zero=True)\n",
    "    ax[0].step(bins, uwpdf, label=aar)\n",
    "    ax[1].step(bins, awcdf)\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlim((0, 200))\n",
    "    ax[0].set_xlabel(\"Tau [yr]\")\n",
    "    print(f\"\\n{aar}\")\n",
    "    print(\"Median:\", weighted_quantile(x, [0.05, 0.5, 0.95])) \n",
    "    print(\"weighted median:\", weighted_quantile(x, [0.05, 0.5, 0.95], sample_weight=d[\"Area\"]))\n",
    "    print(\"Std:\", x.std())\n",
    "    print(\"Skew:\", x.skew())\n",
    "    "
   ],
   "id": "1887738f0dd1fd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "ds_plt = {key: df.loc[:, [\"Area\", \"tau\", \"RGIId\"]] for key, df in ds.items()}\n",
    "d = ds_plt[\"0.4\"]#.rename(columns={\"tau\": \"tau_0.4\"})\n",
    "qcuts = pd.cut(d['Area'], bins=[1,2, 5, 10, 25, 50, 100, 250, 1000, 10000], precision=0)\n",
    "\n",
    "for key in [\"0.6\", \"zeller\"]:\n",
    "    d_merge = ds_plt[key][[col for col in ds_plt[key] if col not in ['Area']]]  # get the df from the dict of cases\n",
    "    print(key)\n",
    "    print(d.columns)\n",
    "    print(d_merge.columns)\n",
    "    d = d.merge(d_merge, on=[\"RGIId\"], suffixes=[\"_0.4\", f\"_{key}\"])  #\n",
    "    print(d.columns)\n",
    "d = d.rename(columns={\"tau\": \"tau_zeller\"})\n",
    "print(d.columns)\n",
    "d[\"qcut\"] = qcuts\n",
    "# Reshape the DataFrame using melt for Seaborn plotting\n",
    "d = pd.melt(\n",
    "    d,\n",
    "    id_vars=[\"RGIId\", \"Area\", \"qcut\"],\n",
    "    value_vars=[col for col in d.columns if col not in [\"RGIId\", \"Area\" \"qcut\"]],\n",
    "    var_name=\"variable\",\n",
    "    value_name=\"value\"\n",
    ")\n",
    "\n",
    "# Extract suffixes and assign them as a new column for hue\n",
    "d[\"suffix\"] = d[\"variable\"].apply(lambda x: x.split(\"_\")[-1]).astype(str)\n",
    "d[\"variable\"] = d[\"variable\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "\n",
    "print(d.columns)"
   ],
   "id": "a2bcef651073bb46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(layout='constrained', dpi=200)\n",
    "sns.boxplot(data=d.loc[d.variable == \"tau\"], x=\"qcut\", y=\"value\", hue='suffix', ax=ax, hue_order=[\"zeller\", \"0.4\", \"0.6\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "(\n",
    "    so.Plot(x=qcuts.cat.categories, y=0, text=[f\"{item:.0f}\" for item in qcuts.value_counts().values/2])\n",
    "    .add(so.Text(fontsize='xx-small',valign='top', offset=5))\n",
    "    .on(ax)\n",
    "    .plot()\n",
    ")\n",
    "ax.grid(which='both', axis='y')\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(25))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(5))\n",
    "ax.set_ylim([-10, 200])\n",
    "ax.set_xlabel('Area (km2)')\n",
    "ax.set_ylabel('Tau (yr)')\n",
    "ax.set_title('Tau')"
   ],
   "id": "d6223243dee15bf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "fig, ax = plt.subplots(layout='constrained', dpi=200)\n",
    "sns.boxplot(data=d.loc[d.variable == \"tau\"], x=\"qcut\", y=\"value\", hue='suffix', ax=ax, hue_order=[\"zeller\", \"0.4\", \"0.6\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "(\n",
    "    so.Plot(x=qcuts.cat.categories, y=0, text=[f\"{item:.0f}\" for item in qcuts.value_counts().values/2])\n",
    "    .add(so.Text(fontsize='xx-small',valign='top', offset=5))\n",
    "    .on(ax)\n",
    "    .plot()\n",
    ")\n",
    "ax.grid(which='both', axis='y')\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(25))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(5))\n",
    "ax.set_ylim([-10, 200])\n",
    "ax.set_xlabel('Area (km2)')\n",
    "ax.set_ylabel('pct diff')\n",
    "ax.set_title('Tau')"
   ],
   "id": "f1dd5dc3c67992f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "for aar, d in ds.items():\n",
    "    sns.histplot(d['feq'], label=aar, fill=False, ax=ax, bins=np.linspace(0, 1, 40), element='step')\n",
    "ax.legend()"
   ],
   "id": "15e3d332f28f85c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(elas.aar, bins=30, label='aar', alpha=0.5)\n",
    "ax.hist(elas.hyps_aar, bins=30, label='hyps_aar', alpha=0.5)\n",
    "ax.legend()"
   ],
   "id": "590c65125dc6c7e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9733a740a7b476bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(np.nanmean(elas.aar))\n",
    "print(np.median(elas.aar))"
   ],
   "id": "b68e0d463d4fb352",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(2,1, sharex=True)\n",
    "binfreq = 0.025\n",
    "for aar, d in ds.items():\n",
    "    x = d['feq_gwi']\n",
    "    uwpdf, bins = hist2(x, binfreq=binfreq, cumsum=False, from_zero=True)\n",
    "    awcdf, bins = hist2(x, area=d['Area'].to_numpy(), binfreq=binfreq, cumsum=True, from_zero=True)\n",
    "    ax[0].step(bins, uwpdf, label=aar)\n",
    "    ax[1].step(bins, awcdf)\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlim((0, 1))\n",
    "    ax[0].set_ylabel(\"feq\")\n",
    "    print(f\"\\n{aar}\")\n",
    "    print(\"Median:\", weighted_quantile(x, [0.05, 0.5, 0.95])) \n",
    "    print(\"weighted median:\", weighted_quantile(x, [0.05, 0.5, 0.95], sample_weight=d[\"Area\"]))\n",
    "    print(\"Std:\", x.std())\n",
    "    print(\"Skew:\", x.skew())\n",
    "    "
   ],
   "id": "96c0df2166135bd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "cols = ['RGIId', 'hf', 'bt', 'tau', 'feq', 'feq_linear', 'feq_gwi', 'feq_etcw', 'Name', 'Zmin', 'Zmax', 'Zela']\n",
    "ds_plt = {key: df.loc[:, cols] for key, df in ds.items()}\n",
    "\n",
    "id_cols = ['RGIId', 'Name', 'Area', 'Zmin', 'Zmax', 'Zela']\n",
    "d = None\n",
    "for key in [\"0.4\", \"0.6\", \"zeller\"]:\n",
    "    if d is None:\n",
    "        # Initialize 'd' with the first dataframe and rename columns\n",
    "        d = ds_plt[key]\n",
    "        d.columns = [\n",
    "            f\"{col}_{key}\" if col not in id_cols else col\n",
    "            for col in d.columns\n",
    "        ]\n",
    "    else:\n",
    "        # Select the dataframe to merge and exclude id_cols from renaming\n",
    "        d_merge = ds_plt[key]\n",
    "        \n",
    "        # Select only the columns that are not in id_cols\n",
    "        cols_to_merge = [col for col in d_merge.columns if col not in id_cols]\n",
    "        \n",
    "        # Rename columns to include the key suffix\n",
    "        d_merge = d_merge[cols_to_merge]\n",
    "        d_merge.columns = [\n",
    "            f\"{col}_{key}\" for col in d_merge.columns\n",
    "        ]\n",
    "        \n",
    "        print(f\"Merging key: {key}\")\n",
    "        print(f\"d columns: {d.columns}\")\n",
    "        print(f\"d_merge columns: {d_merge.columns}\")\n",
    "        \n",
    "        # Merge dataframes on id_cols\n",
    "        d = d.merge(d_merge, left_index=True, right_index=True)  # Merge using index as keys match through index\n",
    "        print(f\"After merge: {d.columns}\")\n",
    "\n"
   ],
   "id": "33961c4e8fe61772",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "combined_df = pd.concat(ds, names=['case', 'index'])\n",
    "# Set the multi-index to include 'RGIId' and 'case'\n",
    "combined_df = combined_df.set_index(['RGIId'], append=True).swaplevel('RGIId', 'index').sort_index().reset_index(level='index', drop=True)\n",
    "\n",
    "cols_to_keep = ['Name', 'Area', 'bt', 'hf', 'tau', 'feq', 'feq_linear', 'feq_gwi', 'feq_etcw', 'Zmin', 'Zmax', 'Zela', 'Lmax', 'aar', 'hyps_ela', 'hyps_aar']\n",
    "combined_df = combined_df[cols_to_keep]\n",
    "combined_df.head(10)"
   ],
   "id": "64259137118a0c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "p = Path(\"TableD1_data.csv\")\n",
    "combined_df.to_csv(p)"
   ],
   "id": "2c31db5a0f9b27f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
